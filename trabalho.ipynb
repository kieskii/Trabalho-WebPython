{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kieskii/Trabalho-WebPython/blob/main/trabalho.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Digits Dataset com Decision Tree e Random Forest\n",
        "\n",
        "- **Objetivo:** Treinar tanto um modelo de árvore de decisão quanto um Random Forest no dataset Digits, e comparar o desempenho de ambos os modelos, especialmente no que diz respeito à capacidade de generalização e ao tempo de execução.\n",
        "\n",
        "- **Técnica:** Comparação entre Decision Tree e Random Forest.\n",
        "\n",
        "---\n",
        "\n",
        "## Descrição dos Desafios:\n",
        "\n",
        "- **Desafios 10:** Introduzem o uso de ensembles simples e a comparação direta entre diferentes classificadores para evidenciar as diferenças entre eles.\n",
        "\n",
        "Esses desafios continuam a usar classificadores básicos e comuns, proporcionando uma base sólida em machine learning enquanto exploram técnicas como ajuste de hiperparâmetros, ensemble learning e análise de erros.\n",
        "\n",
        "---\n",
        "\n",
        "Conteúdo do teste\n",
        "Pergunta <bdi></bdi>\n",
        "Utilizar o banco de dados desbalanceado de covid e buscar atingir o maior resultado que conseguir. Use recursos como: Feature Selection, Sampling, Tuning, Ensemble, Feature Engineering..."
      ],
      "metadata": {
        "id": "LpTih6vsqZmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "train_fold_0 = pd.read_csv('/content/lbp-train-fold_0.csv')\n",
        "train_fold_1 = pd.read_csv('/content/lbp-train-fold_1.csv')\n",
        "train_fold_2 = pd.read_csv('/content/lbp-train-fold_2.csv')\n",
        "train_fold_3 = pd.read_csv('/content/lbp-train-fold_3.csv')\n",
        "train_fold_4 = pd.read_csv('/content/lbp-train-fold_4.csv')\n",
        "\n",
        "train_data = pd.concat([train_fold_0, train_fold_1, train_fold_2, train_fold_3, train_fold_4], ignore_index=True)\n",
        "\n",
        "X = train_data.drop(columns=['class'])\n",
        "y = train_data['class']\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train_scaled, y_train)\n",
        "y_pred_dt = dt_model.predict(X_val_scaled)\n",
        "\n",
        "rf_model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [5, 10, None],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='f1_macro')\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "y_pred_rf = best_rf_model.predict(X_val_scaled)\n",
        "\n",
        "data_test = pd.read_csv('/content/lbp-test.csv')\n",
        "X_test = data_test.drop(columns=['class'])\n",
        "y_test = data_test['class']\n",
        "\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "y_test_pred_dt = dt_model.predict(X_test_scaled)\n",
        "y_test_pred_rf = best_rf_model.predict(X_test_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoZ2GbyUR26I",
        "outputId": "332f07f2-55dc-4ecd-d692-2693ff0936ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Decision Tree F1-Score Macro: 0.3611531733058017\n",
            "Test Set Random Forest F1-Score Macro: 0.31667839549612953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "svm_model = SVC(probability=True, class_weight='balanced')\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "y_pred_svm = svm_model.predict(X_val_scaled)\n",
        "\n",
        "gb_model = GradientBoostingClassifier(random_state=42)\n",
        "gb_model.fit(X_train_scaled, y_train)\n",
        "y_pred_gb = gb_model.predict(X_val_scaled)\n",
        "\n",
        "voting_model = VotingClassifier(estimators=[\n",
        "    ('dt', dt_model),\n",
        "    ('rf', best_rf_model),\n",
        "    ('svm', svm_model),\n",
        "    ('gb', gb_model)],\n",
        "    voting='soft')\n",
        "voting_model.fit(X_train_scaled, y_train)\n",
        "y_pred_voting = voting_model.predict(X_val_scaled)\n",
        "\n",
        "models = {\n",
        "    'Decision Tree': y_pred_dt,\n",
        "    'Random Forest': y_pred_rf,\n",
        "    'SVM': y_pred_svm,\n",
        "    'Gradient Boosting': y_pred_gb,\n",
        "    'Voting Ensemble': y_pred_voting,\n",
        "}\n",
        "\n",
        "for model_name, predictions in models.items():\n",
        "    print(f\"{model_name} F1-Score Macro:\", f1_score(y_val, predictions, average='macro'))\n",
        "\n",
        "y_test_pred_svm = svm_model.predict(X_test_scaled)\n",
        "y_test_pred_gb = gb_model.predict(X_test_scaled)\n",
        "y_test_pred_voting = voting_model.predict(X_test_scaled)\n",
        "\n",
        "test_models = {\n",
        "    'Decision Tree': y_test_pred_dt,\n",
        "    'Random Forest': y_test_pred_rf,\n",
        "    'SVM': y_test_pred_svm,\n",
        "    'Gradient Boosting': y_test_pred_gb,\n",
        "    'Voting Ensemble': y_test_pred_voting,\n",
        "}\n",
        "\n",
        "for model_name, predictions in test_models.items():\n",
        "    print(f\"Test Set {model_name} F1-Score Macro:\", f1_score(y_test, predictions, average='macro'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSdC-Oaa0Uwm",
        "outputId": "a16987c8-7e13-4832-eb6c-2f3c18d6f049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree F1-Score Macro: 0.9758799619179772\n",
            "Random Forest F1-Score Macro: 0.9960020232154271\n",
            "SVM F1-Score Macro: 0.996035848406948\n",
            "Gradient Boosting F1-Score Macro: 0.9960415100139687\n",
            "Voting Ensemble F1-Score Macro: 0.9960876370154178\n",
            "Test Set Decision Tree F1-Score Macro: 0.3611531733058017\n",
            "Test Set Random Forest F1-Score Macro: 0.31667839549612953\n",
            "Test Set SVM F1-Score Macro: 0.38624801413755555\n",
            "Test Set Gradient Boosting F1-Score Macro: 0.27114019393998806\n",
            "Test Set Voting Ensemble F1-Score Macro: 0.3611331099604021\n"
          ]
        }
      ]
    }
  ]
}